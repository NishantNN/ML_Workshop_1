{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing K-means\n",
    "\n",
    "The K-means algorithm is a method to automatically cluster similar\n",
    "data points together. \n",
    "\n",
    "* Concretely, you are given a training set $\\{x^{(1)}, ..., x^{(m)}\\}$, and you want\n",
    "to group the data into a few cohesive “clusters”. \n",
    "\n",
    "\n",
    "* K-means is an iterative procedure that\n",
    "     * Starts by guessing the initial centroids, and then \n",
    "     * Refines this guess by \n",
    "         * Repeatedly assigning examples to their closest centroids, and then \n",
    "         * Recomputing the centroids based on the assignments.\n",
    "         \n",
    "\n",
    "* In pseudocode, the K-means algorithm is as follows:\n",
    "\n",
    "    ``` python\n",
    "    # Initialize centroids\n",
    "    # K is the number of clusters\n",
    "    centroids = kMeans_init_centroids(X, K)\n",
    "    \n",
    "    for iter in range(iterations):\n",
    "        # Cluster assignment step: \n",
    "        # Assign each data point to the closest centroid. \n",
    "        # idx[i] corresponds to the index of the centroid \n",
    "        # assigned to example i\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "\n",
    "        # Move centroid step: \n",
    "        # Compute means based on centroid assignments\n",
    "        centroids = compute_means(X, idx, K)\n",
    "    ```\n",
    "\n",
    "\n",
    "* The inner-loop of the algorithm repeatedly carries out two steps: \n",
    "    * (i) Assigning each training example $x^{(i)}$ to its closest centroid, and\n",
    "    * (ii) Recomputing the mean of each centroid using the points assigned to it. \n",
    "    \n",
    "    \n",
    "* The $K$-means algorithm will always converge to some final set of means for the centroids. \n",
    "\n",
    "* However, that the converged solution may not always be ideal and depends on the initial setting of the centroids.\n",
    "    * Therefore, in practice the K-means algorithm is usually run a few times with different random initializations. \n",
    "    * One way to choose between these different solutions from different random initializations is to choose the one with the lowest cost function value (distortion).\n",
    "\n",
    "You will implement the two phases of the K-means algorithm separately\n",
    "in the next sections. \n",
    "* You will start by completing `find_closest_centroid` and then proceed to complete `compute_centroids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../data/clstr/k_means_clustering_data.csv\")\n",
    "data = df.iloc[:,:2]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.iloc[:,0],data.iloc[:,1])\n",
    "plt.title(\"K-Means Dataset with Two Features\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Our Final Output should look like :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[\"Feature_1\"], df[\"Feature_2\"], c=df[\"Cluster\"], cmap=\"viridis\", s=50, alpha=0.7)\n",
    "plt.title(\"K-Means Dataset with Two Features\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.colorbar(label=\"Cluster Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Finding closest centroids\n",
    "\n",
    "In the “cluster assignment” phase of the K-means algorithm, the\n",
    "algorithm assigns every training example $x^{(i)}$ to its closest\n",
    "centroid, given the current positions of centroids. \n",
    "\n",
    "### Exercise 1\n",
    "\n",
    "Your task is to complete the code in `find_closest_centroids`. \n",
    "* This function takes the data matrix `X` and the locations of all\n",
    "centroids inside `centroids` \n",
    "* It should output a one-dimensional array `idx` (which has the same number of elements as `X`) that holds the index  of the closest centroid (a value in $\\{1,...,K\\}$, where $K$ is total number of centroids) to every training example .\n",
    "* Specifically, for every example $x^{(i)}$ we set\n",
    "$$c^{(i)} := j \\quad \\mathrm{that \\; minimizes} \\quad ||x^{(i)} - \\mu_j||^2,$$\n",
    "where \n",
    " * $c^{(i)}$ is the index of the centroid that is closest to $x^{(i)}$ (corresponds to `idx[i]` in the starter code), and \n",
    " * $\\mu_j$ is the position (value) of the $j$’th centroid. (stored in `centroids` in the starter code)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***pseudocode : ***  \n",
    "`iterate over datapoints {`   \n",
    "`distance = {}` *Empty array to store distances  between a point and centroids*  \n",
    "`iterate over centroids {`  \n",
    "`dist = ?` *calculate the distance using a function*  \n",
    "`distance.append(dist)` *append value to distances array*  \n",
    "`}`  \n",
    "`overwrite current centroud index with new centroid index`  \n",
    "`}`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hint :** use `np.linp.linalg.norm(p1,p2)` to compute distance and `np.argmin(distance)` to find index of minimum value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: find_closest_centroids\n",
    "\n",
    "def find_closest_centroids(X, centroids):\n",
    "    \"\"\"\n",
    "    Computes the centroid memberships for every example\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): (m, n) Input values      \n",
    "        centroids (ndarray): k centroids\n",
    "    \n",
    "    Returns:\n",
    "        idx (array_like): (m,) closest centroids\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Set K\n",
    "    K = centroids.shape[0]\n",
    "\n",
    "    # You need to return the following variables correctly\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now let's check our above function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "print(\"First five datapoints in X are : \\n\", X[:5])\n",
    "print(\"shape of X is \", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an initial set of centroids (3 Centroids)\n",
    "initial_centroids = np.array([[3,3], [-6,2], [-8,-5]])\n",
    "\n",
    "# Find closest centroids using initial_centroids\n",
    "idx = find_closest_centroids(X, initial_centroids)\n",
    "\n",
    "# Print closest centroids for the first three elements\n",
    "print(\"First three elements in idx are:\", idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Computing centroid means\n",
    "\n",
    "Given assignments of every point to a centroid, the second phase of the\n",
    "algorithm recomputes, for each centroid, the mean of the points that\n",
    "were assigned to it.\n",
    "\n",
    "\n",
    "### Exercise 2\n",
    "\n",
    "Please complete the `compute_centroids` below to recompute the value for each centroid\n",
    "\n",
    "* Specifically, for every centroid $\\mu_k$ we set\n",
    "$$\\mu_k = \\frac{1}{|C_k|} \\sum_{i \\in C_k} x^{(i)}$$ \n",
    "\n",
    "where,  \n",
    "*$C_k$ is the set of examples that are assigned to centroid $k$*  \n",
    "*$|C_k|$ is the number of examples in the set $C_k$*  \n",
    "\n",
    "\n",
    "* Concretely, if two examples say $x^{(3)}$ and $x^{(5)}$ are assigned to centroid $k=2$,\n",
    "then you should update $\\mu_2 = \\frac{1}{2}(x^{(3)}+x^{(5)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pseudocode :***  \n",
    "`iterate over centroids {`  \n",
    "`points = {}` *array to store all datapoints of same centroid*  \n",
    "`if centroid of datapoint == current centroid {`  \n",
    "`append the datapaoint to points`  \n",
    "`}`  \n",
    "`current centroid = mean(points)`  \n",
    "`}`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(X, idx, K):\n",
    "    \"\"\"\n",
    "    Returns the new centroids by computing the means of the \n",
    "    data points assigned to each centroid.\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):   (m, n) Data points\n",
    "        idx (ndarray): (m,) Array containing index of closest centroid for each \n",
    "                       example in X. Concretely, idx[i] contains the index of \n",
    "                       the centroid closest to example i\n",
    "        K (int):       number of centroids\n",
    "    \n",
    "    Returns:\n",
    "        centroids (ndarray): (K, n) New centroids computed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Useful variables\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    centroids = np.zeros((K, n))\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    ### END CODE HERE ## \n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check your implementation by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "print(\"The centroids are:\\n\", centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***function to plot progess of the algorithm***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_progress_kMeans(X, centroids, previous_centroids, idx, K, i):\n",
    "    # Plot the examples\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=idx)\n",
    "    \n",
    "    # Plot the centroids as black 'x's\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', c='k', linewidths=3)\n",
    "    \n",
    "    # Plot history of the centroids with lines\n",
    "    for j in range(centroids.shape[0]):\n",
    "        p1 = centroids[j,:]\n",
    "        p2 = previous_centroids[j,:]\n",
    "        plt.plot([p1[0], p2[0]], [p1[1], p2[1]], \"-k\", linewidth=1)\n",
    "    \n",
    "    plt.title(\"Iteration number %d\" %i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Running the k-means algorithm***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You do not need to implement anything for this part\n",
    "\n",
    "def run_kMeans(X, initial_centroids, max_iters=10, plot_progress=False):\n",
    "    \"\"\"\n",
    "    Runs the K-Means algorithm on data matrix X, where each row of X\n",
    "    is a single example\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize values\n",
    "    m, n = X.shape\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    previous_centroids = centroids    \n",
    "    idx = np.zeros(m)\n",
    "    \n",
    "    # Run K-Means\n",
    "    for i in range(max_iters):\n",
    "        \n",
    "        #Output progress\n",
    "        print(\"K-Means iteration %d/%d\" % (i, max_iters-1))\n",
    "        \n",
    "        # For each example in X, assign it to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Optionally plot progress\n",
    "        if plot_progress:\n",
    "            plot_progress_kMeans(X, centroids, previous_centroids, idx, K, i)\n",
    "            previous_centroids = centroids\n",
    "            \n",
    "        # Given the memberships, compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "    plt.show() \n",
    "    return centroids, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of centroids\n",
    "init_centroids = np.array([[3,3], [-6,2], [-8,-5]])\n",
    "# Number of iterations\n",
    "max_iters = 10\n",
    "\n",
    "centroids, idx = run_kMeans(X, init_centroids, max_iters, plot_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of centroids\n",
    "init_centroids = \n",
    "# Number of iterations\n",
    "max_iters =\n",
    "\n",
    "centroids, idx = run_kMeans(X, init_centroids, max_iters, plot_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Random initialization\n",
    "We implemented the above algorithm by manually asaigning the centroids.\n",
    "In practice, a good strategy for initializing the centroids is to select random examples from the\n",
    "training set.\n",
    "\n",
    "In this part of the exercise, you should understand how the function `kMeans_init_centroids` is implemented.\n",
    "* The code first randomly shuffles the indices of the examples (using `np.random.permutation()`). \n",
    "* Then, it selects the first $K$ examples based on the random permutation of the indices. \n",
    "    * This allows the examples to be selected at random without the risk of selecting the same example twice.\n",
    "\n",
    "**Note**: You do not need to make implement anything for this part of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You do not need to modify this part\n",
    "\n",
    "def kMeans_init_centroids(X, K):\n",
    "    \"\"\"\n",
    "    This function initializes K centroids that are to be \n",
    "    used in K-Means on the dataset X\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray): Data points \n",
    "        K (int):     number of centroids/clusters\n",
    "    \n",
    "    Returns:\n",
    "        centroids (ndarray): Initialized centroids\n",
    "    \"\"\"\n",
    "    \n",
    "    # Randomly reorder the indices of examples\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    \n",
    "    # Take the first K examples as centroids\n",
    "    centroids = X[randidx[:K]]\n",
    "    \n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of centroids\n",
    "k = 4 # k = number of centroids\n",
    "init_centroids = kMeans_init_centroids(X,k)\n",
    "# Number of iterations\n",
    "max_iters = 10\n",
    "\n",
    "centroids, idx = run_kMeans(X, init_centroids, max_iters, plot_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
